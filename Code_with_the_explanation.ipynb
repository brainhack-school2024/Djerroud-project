{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import librosa  # Importation de la bibliothèque librosa pour le traitement audio\n",
        "import librosa.display  # Importation de la fonction de visualisation de librosa\n",
        "import matplotlib.pyplot as plt  # Importation de matplotlib pour la visualisation"
      ],
      "metadata": {
        "id": "LARkxVcj7N_H"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition des chemins vers les fichiers audio\n",
        "audio_path_1 = '../../data/audio/friends_s01e01a_audio.mp3'  # Chemin vers le premier fichier audio\n",
        "audio_path_2 = '../../data/audio/friends_s01e01b_audio.mp3'  # Chemin vers le deuxième fichier audio\n",
        "\n",
        "# Chargement des fichiers audio\n",
        "y_1, sr_1 = librosa.load(audio_path_1)  # librosa : charge le premier fichier audio dans un tableau d'échantillons (y_1) et un taux d'échantillonnage (sr_1)\n",
        "y_2, sr_2 = librosa.load(audio_path_2)  # librosa : charge le deuxième fichier audio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "iSUOy0hz7QAq",
        "outputId": "fdbbd9b7-9253-4338-ceda-a8b0dd085217"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-ce9e24ecf3b9>:6: UserWarning: PySoundFile failed. Trying audioread instead.\n",
            "  y_1, sr_1 = librosa.load(audio_path_1)  # librosa : charge le premier fichier audio dans un tableau d'échantillons (y_1) et un taux d'échantillonnage (sr_1)\n",
            "/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py:184: FutureWarning: librosa.core.audio.__audioread_load\n",
            "\tDeprecated as of librosa version 0.10.0.\n",
            "\tIt will be removed in librosa version 1.0.\n",
            "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '../../data/audio/friends_s01e01a_audio.mp3'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;31m# Otherwise, create the soundfile object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'r+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Error opening {0!r}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '../../data/audio/friends_s01e01a_audio.mp3': System error.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ce9e24ecf3b9>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Chargement des fichiers audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0my_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# librosa : charge le premier fichier audio dans un tableau d'échantillons (y_1) et un taux d'échantillonnage (sr_1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0my_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_path_2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# librosa : charge le deuxième fichier audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    182\u001b[0m                     \u001b[0;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 )\n\u001b[0;32m--> 184\u001b[0;31m                 \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-157>\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/util/decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         )\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mreader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \"\"\"\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/audio/friends_s01e01a_audio.mp3'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tracé de l'onde des fichiers audio\n",
        "plt.figure(figsize=(12, 6))  # matplotlib : définit la taille de la figure\n",
        "\n",
        "plt.subplot(2, 1, 1)  # matplotlib : crée un sous-plot pour le premier graphique\n",
        "librosa.display.waveshow(y_1, sr=sr_1)  # librosa.display : affiche l'onde du premier fichier audio\n",
        "plt.title('Waveform of Audio 1')  # matplotlib : définit le titre du premier graphique\n",
        "\n",
        "plt.subplot(2, 1, 2)  # matplotlib : crée un sous-plot pour le deuxième graphique\n",
        "librosa.display.waveshow(y_2, sr=sr_2)  # librosa.display : affiche l'onde du deuxième fichier audio\n",
        "plt.title('Waveform of Audio 2')  # matplotlib : définit le titre du deuxième graphique\n",
        "\n",
        "plt.tight_layout()  # matplotlib : ajuste les espaces entre les sous-plots\n",
        "plt.show()  # matplotlib : affiche la figure"
      ],
      "metadata": {
        "id": "l4FkI45l7S_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extraction des caractéristiques MFCC des fichiers audio\n",
        "mfcc_1 = librosa.feature.mfcc(y=y_1, sr=sr_1)  # librosa : extrait les coefficients cepstraux en fréquence Mel (MFCC) du premier fichier audio\n",
        "mfcc_2 = librosa.feature.mfcc(y=y_2, sr=sr_2)  # librosa : extrait les MFCC du deuxième fichier audio\n",
        "\n",
        "# Tracé des caractéristiques MFCC\n",
        "plt.figure(figsize=(12, 6))  # matplotlib : définit la taille de la figure\n",
        "\n",
        "plt.subplot(2, 1, 1)  # matplotlib : crée un sous-plot pour le premier graphique\n",
        "librosa.display.specshow(mfcc_1, x_axis='time')  # librosa.display : affiche les MFCC du premier fichier audio\n",
        "plt.colorbar()  # matplotlib : ajoute une barre de couleur pour l'échelle\n",
        "plt.title('MFCC of Audio 1')  # matplotlib : définit le titre du premier graphique\n",
        "\n",
        "plt.subplot(2, 1, 2)  # matplotlib : crée un sous-plot pour le deuxième graphique\n",
        "librosa.display.specshow(mfcc_2, x_axis='time')  # librosa.display : affiche les MFCC du deuxième fichier audio\n",
        "plt.colorbar()  # matplotlib : ajoute une barre de couleur pour l'échelle\n",
        "plt.title('MFCC of Audio 2')  # matplotlib : définit le titre du deuxième graphique\n",
        "\n",
        "plt.tight_layout()  # matplotlib : ajuste les espaces entre les sous-plots\n",
        "plt.show()  # matplotlib : affiche la figure"
      ],
      "metadata": {
        "id": "-BceHpeL7y9q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Importation de la bibliothèque os pour manipuler les chemins de fichiers\n",
        "import json  # Importation de la bibliothèque json pour charger les fichiers JSON"
      ],
      "metadata": {
        "id": "qUP8Ni5571VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Définition du répertoire contenant les fichiers JSON et le chemin du fichier JSON\n",
        "json_dir = os.path.expanduser(\"~/Documents/BrainHack/BrainHack_projects/data/json/json_aa/json_aa\")  # os : développement du chemin vers le répertoire JSON\n",
        "json_file = os.path.join(json_dir, \"friends_s01e01a_aa.json\")  # os : création du chemin complet vers le fichier JSON"
      ],
      "metadata": {
        "id": "4t1ctiAP72cK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeP-uks4Isli"
      },
      "outputs": [],
      "source": [
        "# Chargement du fichier JSON\n",
        "with open(json_file, 'r') as file:  # Ouverture du fichier JSON en mode lecture\n",
        "    data = json.load(file)  # json : chargement du contenu du fichier JSON dans une variable data\n",
        "\n",
        "data.keys()  # Affichage des clés du dictionnaire JSON\n",
        "\n",
        "data[\"results\"][\"channels\"][0]['alternatives'][0][\"words\"]  # Accès aux mots transcrits dans le JSON\n",
        "\n",
        "y, sr = librosa.load(audio_file, sr=None)  # librosa : chargement d'un fichier audio dans y et sr\n",
        "sr  # Affichage du taux d'échantillonnage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import assemblyai as aai  # Importation de la bibliothèque AssemblyAI pour la transcription audio\n",
        "\n",
        "# API key\n",
        "aai.settings.api_key = \"c52b0e5efa6a41cabab766bf87419e2e\"  # Configuration de la clé API pour accéder à AssemblyAI\n",
        "\n",
        "# URL of the file to transcribe\n",
        "FILE_URL = \"https://assemblyaiusercontent.com/playground/4jigmcKoY4o.mp3\"  # Définition de l'URL du fichier audio à transcrire\n",
        "\n",
        "# Configure transcription parameters\n",
        "config = aai.TranscriptionConfig(  # Utilisation de AssemblyAI pour configurer les paramètres de transcription\n",
        "    speech_model=aai.SpeechModel.best,  # Spécifie le modèle de parole à utiliser\n",
        "    iab_categories=True,  # Active l'analyse des catégories IAB\n",
        "    sentiment_analysis=True,  # Active l'analyse de sentiment\n",
        "    entity_detection=True,  # Active la détection d'entités\n",
        "    speaker_labels=True,  # Active l'étiquetage des intervenants\n",
        "    language_code=\"en_us\"  # Définit le code de langue pour l'audio\n",
        ")"
      ],
      "metadata": {
        "id": "kNxKb0zQ8C3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create transcriber instance with the provided configuration\n",
        "transcriber = aai.Transcriber(config=config)  # Création d'une instance de transcripteur avec la configuration spécifiée\n",
        "\n",
        "# Transcribe the audio file\n",
        "transcript = transcriber.transcribe(FILE_URL)  # Transcription du fichier audio via AssemblyAI\n",
        "\n",
        "# Check the transcription status and print results\n",
        "if transcript.status == aai.TranscriptStatus.error:  # Vérifie si la transcription a échoué\n",
        "    print(f\"Error: {transcript.error}\")  # Affiche l'erreur si la transcription a échoué\n",
        "else:\n",
        "    # Print the transcription text with speaker labels if available\n",
        "    if hasattr(transcript, 'utterances') and transcript.utterances:  # Vérifie si les énoncés sont disponibles\n",
        "        print(\"Transcription with Speaker Labels:\")  # Indique que la transcription inclut des étiquettes d'intervenants\n",
        "        for utterance in transcript.utterances:  # Itère à travers les énoncés\n",
        "            speaker = utterance.speaker  # Obtient le nom de l'intervenant\n",
        "            text = utterance.text  # Obtient le texte de l'énoncé\n",
        "            print(f\"Speaker {speaker}: {text}\")  # Affiche le texte avec l'étiquette de l'intervenant\n",
        "    else:\n",
        "        print(\"Transcription:\")  # Indique que la transcription est simple\n",
        "        print(transcript.text)  # Affiche le texte de la transcription\n",
        "\n",
        "    # Print the detected entities\n",
        "    if hasattr(transcript, 'entities') and transcript.entities:  # Vérifie si des entités ont été détectées\n",
        "        print(\"\\nEntities Detected:\")  # Indique que des entités ont été détectées\n",
        "        for entity in transcript.entities:  # Itère à travers les entités détectées\n",
        "            print(f\"Type: {entity.entity_type}, Text: {entity.text}\")  # Affiche le type et le texte de chaque entité"
      ],
      "metadata": {
        "id": "nMw0KnFG76Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Importation de la bibliothèque os pour manipuler les chemins de fichiers\n",
        "import pandas as pd  # Importation de la bibliothèque pandas pour la manipulation de données\n",
        "import re  # Importation de la bibliothèque re pour les expressions régulières\n",
        "from textblob import TextBlob  # Importation de TextBlob pour l'analyse de sentiment\n",
        "import sqlite3  # Importation de sqlite3 pour interagir avec des bases de données SQLite\n",
        "import matplotlib  # Importation de matplotlib pour la visualisation\n",
        "import matplotlib.pyplot as plt  # Importation de matplotlib.pyplot pour créer des graphiques\n",
        "from IPython.display import set_matplotlib_formats  # Importation pour définir les formats d'affichage dans IPython\n",
        "import warnings  # Importation de la bibliothèque warnings pour gérer les avertissements"
      ],
      "metadata": {
        "id": "jknD8P6u8HwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')  # Ignore les avertissements\n",
        "\n",
        "# Clear the font cache manually (if necessary)\n",
        "font_cache_dir = os.path.join(matplotlib.get_cachedir(), 'fontlist-v330.json')  # Chemin vers le cache de police\n",
        "if os.path.exists(font_cache_dir):  # Vérifie si le fichier de cache existe\n",
        "    os.remove(font_cache_dir)  # Supprime le fichier de cache de police s'il existe\n",
        "\n",
        "# Rebuild the font cache using findSystemFonts and findfont\n",
        "import matplotlib.font_manager as fm  # Importation pour gérer les polices dans matplotlib\n",
        "fm.findSystemFonts(fontpaths=None, fontext='ttf')  # Recherche les polices système\n",
        "fm.findfont('serif')  # Rechercher la police \"serif\"\n",
        "\n",
        "# Set display format for IPython\n",
        "set_matplotlib_formats('retina', quality=100)  # Configure le format d'affichage pour IPython"
      ],
      "metadata": {
        "id": "nmo73BUF8zQj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a DataFrame\n",
        "df = pd.DataFrame(master_array, columns=['season', 'episode', 'char', 'line'])  # Création d'un DataFrame à partir de master_array\n",
        "\n",
        "# Displaying unique characters\n",
        "df['char'].unique()[20:30]  # Affiche les caractères uniques dans la colonne 'char'\n",
        "\n",
        "# Normalize character names\n",
        "df['char'].replace({  # Utilise pandas pour normaliser les noms des personnages\n",
        "    'Chandler':'Chandler',\n",
        "    'CHANDLER':'Chandler',\n",
        "    'Chandlers':'Chandler',\n",
        "    'chandler': 'Chandler',\n",
        "    'Joey':'Joey',\n",
        "    'JOEY': 'Joey',\n",
        "    'Monica':'Monica',\n",
        "    'MONICA':'Monica',\n",
        "    'MOnica': 'Monica',\n",
        "    'MNCA': 'Monica',\n",
        "    'Phoebe':'Phoebe',\n",
        "    'PHOEBE':'Phoebe',\n",
        "    'Pheebs':'Phoebe',\n",
        "    'Rachel':'Rachel',\n",
        "    'RACHEL':'Rachel',\n",
        "    'RACH':'Rachel',\n",
        "    'RAHCEL':'Rachel',\n",
        "    'Racel':'Rachel',\n",
        "    'Rache':'Rachel',\n",
        "    'Ross':'Ross',\n",
        "    'RUSS':'Ross',\n",
        "    'ROSS': 'Ross'\n",
        "}, inplace=True)  # Remplace les variations des noms par un format standard\n",
        "\n",
        "# Filter DataFrame for specific characters\n",
        "char = ['Chandler', 'Joey', 'Monica', 'Phoebe', 'Rachel', 'Ross']  # Liste des personnages à conserver\n",
        "df = df[df['char'].isin(char)]  # Filtre le DataFrame pour inclure uniquement les personnages spécifiés\n",
        "\n",
        "# Perform sentiment analysis\n",
        "df['sentiment'] = df['line'].apply(lambda x: TextBlob(x).sentiment[0])  # Utilise TextBlob pour analyser le sentiment de chaque ligne\n",
        "df['season'] = df['season'].apply(lambda x: int(x))  # Utilise pandas pour convertir les valeurs de la colonne 'season' en entiers\n",
        "df['episode'] = df['episode'].apply(lambda x: int(x))  # Utilise pandas pour convertir les valeurs de la colonne 'episode' en entiers\n"
      ],
      "metadata": {
        "id": "W1pWUshIK4uN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('friends_script.db')  # sqlite3 : connexion à la base de données SQLite\n",
        "cur = conn.cursor()  # sqlite3 : création d'un curseur pour exécuter des requêtes SQL\n",
        "\n",
        "cur.execute('CREATE TABLE IF NOT EXISTS Friends(season number, episode number, char text, line text, sentiment integer)')  # sqlite3 : création de la table 'Friends' si elle n'existe pas\n",
        "conn.commit()  # sqlite3 : enregistrement des modifications dans la base de données\n",
        "\n",
        "df.to_sql('Friends', conn, if_exists='replace', index=False)  # pandas : sauvegarde le DataFrame dans la table 'Friends' de la base de données\n",
        "\n",
        "COLORS=['#40E0D0', '#4682B4', '#708090', '#90EE90', '#FFDEAD', '#E9967A']  # Liste de couleurs pour les graphiques\n",
        "\n",
        "cur.execute(\"SELECT char, COUNT(line) AS 'spoken_lines' FROM Friends GROUP BY char ORDER BY spoken_lines DESC\")  # sqlite3 : exécute une requête pour compter le nombre de lignes parlées par chaque personnage\n",
        "most_lines = [c for c in cur.fetchall()]  # sqlite3 : récupère les résultats de la requête sous forme de liste\n",
        "\n",
        "print(most_lines)  # Affiche le nombre de lignes parlées par chaque personnage\n",
        "\n",
        "%matplotlib inline  # Commande IPython pour afficher les graphiques dans le notebook"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "CB6Nc_fJ8N4L",
        "outputId": "02617f21-50df-46c3-eaf8-59b49ceb8795"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5b69ba1fda46>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Filter DataFrame for specific characters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mchar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Chandler'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Joey'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Monica'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Phoebe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Rachel'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Ross'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Liste des personnages à conserver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'char'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Filtre le DataFrame pour inclure uniquement les personnages spécifiés\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Perform sentiment analysis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt  # matplotlib : importation pour créer des graphiques\n",
        "\n",
        "# Define your data\n",
        "most_lines = [('Rachel', 9249), ('Ross', 9070), ('Monica', 8380), ('Chandler', 8353), ('Joey', 8169), ('Phoebe', 7394)]  # Définit les données à tracer\n",
        "\n",
        "# Extracting data for plotting\n",
        "characters = [line[0] for line in most_lines]  # Utilise une compréhension de liste pour extraire les noms des personnages\n",
        "lines_count = [line[1] for line in most_lines]  # Utilise une compréhension de liste pour extraire le nombre de lignes\n",
        "\n",
        "# Define colors for each character\n",
        "colors = ['skyblue', 'salmon', 'lightgreen', 'purple', 'orange', 'lightcoral']  # Définit les couleurs pour chaque personnage"
      ],
      "metadata": {
        "id": "rivUFeQ286wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the bar plot with custom colors\n",
        "plt.figure(figsize=(10, 6))  # matplotlib : définit la taille de la figure\n",
        "plt.bar(characters, lines_count, color=colors)  # matplotlib : crée un graphique à barres avec les personnages et le nombre de lignes\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Character')  # matplotlib : ajoute une étiquette pour l'axe des x\n",
        "plt.ylabel('Number of Lines')  # matplotlib : ajoute une étiquette pour l'axe des y\n",
        "plt.title('Number of Lines for the Entire Show')  # matplotlib : définit le titre du graphique\n",
        "\n",
        "# Show plot\n",
        "plt.show()  # matplotlib : affiche le graphique"
      ],
      "metadata": {
        "id": "HVliZbRN9Isq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cur.execute(\"\"\"\n",
        "SELECT char, season, count(line) AS total_lines FROM Friends\n",
        "WHERE char IN ('Rachel', 'Ross', 'Monica','Chandler','Joey', 'Phoebe') GROUP BY season, char\"\"\")  # sqlite3 : exécute une requête pour compter le nombre total de lignes par personnage et par saison\n",
        "lines_per_season = [c for c in cur.fetchall()]  # sqlite3 : récupère les résultats de la requête sous forme de liste\n",
        "lines_dict = {}  # Crée un dictionnaire pour stocker le nombre de lignes par personnage et par saison\n",
        "\n",
        "for lines in lines_per_season:  # Itère à travers les résultats\n",
        "    char = lines[0]  # Récupère le nom du personnage\n",
        "    season = lines[1]  # Récupère la saison\n",
        "    total_lines = lines[2]  # Récupère le nombre total de lignes\n",
        "\n",
        "    if char in lines_dict:  # Vérifie si le personnage est déjà dans le dictionnaire\n",
        "        lines_dict[char][season] = total_lines  # Ajoute le nombre total de lignes pour cette saison\n",
        "    else:\n",
        "        lines_dict[char] = {  # Crée une nouvelle entrée pour ce personnage\n",
        "            season: total_lines\n",
        "        }\n",
        "\n",
        "fig, ax = plt.subplots()  # matplotlib : crée une nouvelle figure et des axes\n",
        "plt.rcParams['figure.figsize'] = (10, 8)  # Définit la taille de la figure\n",
        "for char in lines_dict.keys():  # Itère à travers chaque personnage dans le dictionnaire\n",
        "    x1 = lines_dict[char].keys()  # Récupère les saisons\n",
        "    y1 = lines_dict[char].values()  # Récupère le nombre de lignes\n",
        "    plt.plot(x1, y1, label = char)  # Trace le nombre de lignes par saison pour chaque personnage\n",
        "\n",
        "plt.xlabel('Season')  # matplotlib : ajoute une étiquette pour l'axe des x\n",
        "plt.ylabel('Number of Lines')  # matplotlib : ajoute une étiquette pour l'axe des y\n",
        "plt.title('Number of lines by season')  # matplotlib : définit le titre du graphique\n",
        "plt.legend(loc=1)  # matplotlib : ajoute une légende\n",
        "plt.show()  # matplotlib : affiche le graphique\n",
        "\n",
        "nicknames = [['Rachel', 'Rach'],  # Liste des surnoms pour chaque personnage\n",
        "             ['Ross', 'Ross-A-Tron', 'Professor Geller'],\n",
        "             ['Monica', 'Mon'],\n",
        "             ['Chandler', 'Chan'],\n",
        "             ['Joey', 'Joe'],\n",
        "             ['Phoebe', 'Phoebes']]\n"
      ],
      "metadata": {
        "id": "Mv7KtLaL9M_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_lines = pd.read_sql(\"SELECT line FROM Friends\", conn)  # pandas : exécute une requête SQL pour récupérer toutes les lignes de la table 'Friends'\n",
        "char_mention = []  # Liste pour stocker les mentions de chaque personnage\n",
        "\n",
        "for name_list in nicknames:  # Itère à travers chaque liste de surnoms\n",
        "    mention_counter = 0  # Compteur pour suivre les mentions\n",
        "    for name in name_list:  # Itère à travers chaque surnom\n",
        "        mentions = all_lines['line'].str.count(name).sum()  # Compte le nombre de fois où le surnom apparaît dans les lignes\n",
        "        mention_counter += mentions  # Ajoute le nombre de mentions au compteur\n",
        "    char_mention.append([name_list[0], mention_counter])  # Ajoute le personnage et le compteur de mentions à la liste\n",
        "char_mention = sorted(char_mention, key=lambda x: x[1], reverse=True)  # Trie la liste par nombre de mentions\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (10, 6)  # Définit la taille de la figure\n",
        "fig, ax = plt.subplots()  # Crée une nouvelle figure et des axes\n",
        "plt.bar(  # Crée un graphique à barres\n",
        "    x=[mention[0] for mention in char_mention],  # Utilise les noms des personnages\n",
        "    height=[mention[1] for mention in char_mention],  # Utilise le compteur de mentions\n",
        "    color=COLORS  # Définit les couleurs pour les barres\n",
        ")\n",
        "plt.title('Number of mentions in the script')  # Définit le titre du graphique\n",
        "plt.ylabel('No. of mentions')  # Ajoute une étiquette pour l'axe des y\n",
        "fig.tight_layout()  # Ajuste la mise en page\n",
        "\n",
        "# Function to remove all non-alphabetical characters and keep spaces\n",
        "def alphanumonly(text):  # Définition d'une fonction pour nettoyer le texte\n",
        "    '''Remove all non letters from string'''\n",
        "    regex = re.compile('[^a-zA-Z ]')  # Compile une expression régulière pour supprimer les caractères non alphabétiques\n",
        "    return(regex.sub('', text))  # Supprime les caractères non alphabétiques du texte\n",
        "\n",
        "cur.execute(\"SELECT char, line FROM Friends WHERE char IN ('Rachel', 'Ross', 'Monica','Chandler','Joey', 'Phoebe')\")  # sqlite3 : exécute une requête pour récupérer les lignes des personnages spécifiés\n",
        "lines_per_season = [c for c in cur.fetchall()]  # sqlite3 : récupère les résultats"
      ],
      "metadata": {
        "id": "wAgWLn_jP-50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize vocab sets for each character\n",
        "monica_vocab = set()  # Crée un ensemble pour le vocabulaire de Monica\n",
        "chandler_vocab = set()  # Crée un ensemble pour le vocabulaire de Chandler\n",
        "ross_vocab = set()  # Crée un ensemble pour le vocabulaire de Ross\n",
        "phoebe_vocab = set()  # Crée un ensemble pour le vocabulaire de Phoebe\n",
        "rachel_vocab = set()  # Crée un ensemble pour le vocabulaire de Rachel\n",
        "joey_vocab = set()  # Crée un ensemble pour le vocabulaire de Joey\n",
        "\n",
        "for l in lines_per_season:  # Itère à travers les lignes récupérées\n",
        "    char = l[0]  # Récupère le nom du personnage\n",
        "    l = alphanumonly(l[1]).strip()  # Nettoie la ligne et enlève les espaces\n",
        "    split_words = l.split(' ')  # Sépare la ligne en mots\n",
        "    for word in split_words:  # Itère à travers les mots\n",
        "        if char == 'Monica':  # Vérifie si le personnage est Monica\n",
        "            monica_vocab.add(word)  # Ajoute le mot à son vocabulaire\n",
        "\n",
        "        if char == 'Joey':  # Vérifie si le personnage est Joey\n",
        "            joey_vocab.add(word)  # Ajoute le mot à son vocabulaire\n",
        "\n",
        "        if char == 'Ross':  # Vérifie si le personnage est Ross\n",
        "            ross_vocab.add(word)  # Ajoute le mot à son vocabulaire\n",
        "\n",
        "        if char == 'Phoebe':  # Vérifie si le personnage est Phoebe\n",
        "            phoebe_vocab.add(word)  # Ajoute le mot à son vocabulaire\n",
        "\n",
        "        if char == 'Chandler':  # Vérifie si le personnage est Chandler\n",
        "            chandler_vocab.add(word)  # Ajoute le mot à son vocabulaire\n",
        "\n",
        "        if char == 'Rachel':  # Vérifie si le personnage est Rachel\n",
        "            rachel_vocab.add(word)  # Ajoute le mot à son vocabulaire\n",
        "\n",
        "char_vocal_length = ['Ross', 'Joey', 'Chandler', 'Rachel', 'Phoebe', 'Monica']  # Liste des personnages\n",
        "vocab_lengths = [len(ross_vocab), len(joey_vocab), len(chandler_vocab), len(rachel_vocab), len(phoebe_vocab), len(monica_vocab)]  # Récupère la longueur du vocabulaire de chaque personnage\n"
      ],
      "metadata": {
        "id": "PrUo4NBuMFQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['figure.figsize'] = (10, 6)  # Définit la taille de la figure\n",
        "fig, ax = plt.subplots()  # Crée une nouvelle figure et des axes\n",
        "plt.bar(  # Crée un graphique à barres\n",
        "    x=char_vocal_length,  # Utilise les personnages pour l'axe x\n",
        "    height=vocab_lengths,  # Utilise les longueurs de vocabulaire pour l'axe y\n",
        "    color=COLORS  # Définit les couleurs pour les barres\n",
        ")\n",
        "plt.title('Largest Vocabulary')  # Définit le titre du graphique\n",
        "plt.ylabel('Number of unique words')  # Ajoute une étiquette pour l'axe des y\n",
        "fig.tight_layout()  # Ajuste la mise en page\n",
        "\n",
        "cur.execute(\"SELECT season, episode, sentiment FROM Friends WHERE char == 'Ross' ORDER BY season, episode\")  # sqlite3 : exécute une requête pour récupérer les sentiments de Ross par saison et épisode\n",
        "ross_sentiments = [c for c in cur.fetchall()]  # sqlite3 : récupère les résultats\n",
        "ross_sentiment = {}  # Crée un dictionnaire pour stocker les sentiments de Ross\n",
        "\n",
        "for r in ross_sentiments:  # Itère à travers les sentiments récupérés\n",
        "    season_episode = f'S{r[0]}E{r[1]}'  # Crée une chaîne pour représenter la saison et l'épisode\n",
        "    if r[0] == 10:  # Vérifie si la saison est 10\n",
        "        season_episode = f'STENE{r[1]}'  # Modifie la chaîne pour la saison 10\n",
        "    sentiment = r[2]  # Récupère le sentiment\n",
        "    if season_episode in ross_sentiment:  # Vérifie si la saison et l'épisode existent déjà dans le dictionnaire\n",
        "        ross_sentiment[season_episode] += sentiment  # Ajoute le sentiment à la valeur existante\n",
        "    else:\n",
        "        ross_sentiment[season_episode] = sentiment  # Crée une nouvelle entrée dans le dictionnaire\n",
        "\n",
        "plt.rcParams['figure.figsize'] = (14, 5)  # Définit la taille de la figure\n",
        "seasons = ['S1', 'S2', 'S3', 'S4', 'S5', 'S6', 'S7', 'S8', 'S9', 'STEN']  # Liste des saisons\n",
        "for season in seasons[0:3]:  # Itère à travers les trois premières saisons\n",
        "    sentiments = list(filter(lambda item: item[0].startswith(season), ross_sentiment.items()))  # Filtre les sentiments pour la saison\n",
        "    x1 = list(range(1, len(sentiments)+1))  # Crée une liste d'épisodes\n",
        "    y1 = [x[1] for x in sentiments]  # Récupère les sentiments pour les épisodes\n",
        "    plt.plot(x1, y1, label=season)  # Trace les sentiments par épisode pour chaque saison\n",
        "\n",
        "plt.xlabel('Episode Number')  # matplotlib : ajoute une étiquette pour l'axe des x\n",
        "plt.ylabel('Sentiment Score')  # matplotlib : ajoute une étiquette pour l'axe des y\n",
        "plt.title('Ross Sentiment per Episode in Seasons 1 to Season 3')  # matplotlib : définit le titre du graphique\n",
        "plt.legend(loc=1)  # matplotlib : ajoute une légende\n",
        "plt.show()  # matplotlib : affiche le graphique"
      ],
      "metadata": {
        "id": "Dn1GiYN9QCfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the frequency of interaction between characters\n",
        "interaction_frequency = df.groupby(['char']).size().reset_index(name='interaction_count')  # Utilise pandas pour grouper par personnage et compter les interactions\n",
        "print(\"Frequency of Interaction:\")  # Affiche un message\n",
        "print(interaction_frequency)  # Affiche le DataFrame des fréquences d'interaction\n",
        "\n",
        "# Calculate the percentage of shared vocabulary\n",
        "percentages = []  # Crée une liste pour stocker les pourcentages\n",
        "for idx, row in result_df.iterrows():  # Utilise pandas pour itérer sur chaque ligne du DataFrame result_df\n",
        "    char1 = row['Character 1']  # Récupère le nom du premier personnage\n",
        "    char2 = row['Character 2']  # Récupère le nom du deuxième personnage\n",
        "    shared_terms = row['Shared Vocabulary']  # Récupère le vocabulaire partagé\n",
        "\n",
        "    # Total unique terms for each character\n",
        "    total_terms_char1 = sum(shared_vocabulary[char1].values())  # Calcule le total des termes uniques pour le personnage 1\n",
        "    total_terms_char2 = sum(shared_vocabulary[char2].values())  # Calcule le total des termes uniques pour le personnage 2\n",
        "\n",
        "    # Calculate percentage\n",
        "    percentage = (len(shared_terms) / min(total_terms_char1, total_terms_char2)) * 100  # Calcule le pourcentage de vocabulaire partagé\n",
        "    percentages.append(percentage)  # Ajoute le pourcentage à la liste"
      ],
      "metadata": {
        "id": "AJdkfGTrQLUA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add percentages to DataFrame\n",
        "result_df['Percentage'] = percentages  # Ajoute les pourcentages au DataFrame result_df\n",
        "\n",
        "# Find the maximum percentage\n",
        "max_percentage = result_df['Percentage'].max()  # Trouve le pourcentage maximum dans le DataFrame\n",
        "\n",
        "# Normalize percentages on a 100% scale\n",
        "result_df['Percentage'] = (result_df['Percentage'] / max_percentage) * 100  # Normalise les pourcentages sur une échelle de 100%\n",
        "\n",
        "# Display DataFrame with normalized percentages\n",
        "print(result_df)  # Affiche le DataFrame avec les pourcentages normalisés"
      ],
      "metadata": {
        "id": "GQF9tkT9QN5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Importation de pandas pour la manipulation de données\n",
        "from textblob import TextBlob  # Importation de TextBlob pour l'analyse de sentiment\n",
        "\n",
        "# Perform sentiment analysis on the dialogue data\n",
        "df['sentiment'] = df['line'].apply(lambda x: TextBlob(x).sentiment.polarity)  # Utilise TextBlob pour calculer le score de sentiment des lignes de dialogue\n",
        "\n",
        "# Filter dialogue with positive sentiment (threshold can be adjusted)\n",
        "positive_dialogue = df[df['sentiment'] > 0]  # Filtre les lignes avec un sentiment positif\n",
        "\n",
        "# Display positive emotional expressions\n",
        "positive_dialogue[['char', 'line']]  # Affiche les dialogues positifs avec les personnages"
      ],
      "metadata": {
        "id": "iqdQxhAuQQeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Importation de pandas pour la manipulation de données\n",
        "\n",
        "# Calculate the number of lines spoken by each character across all seasons\n",
        "line_counts = df['char'].value_counts()  # Compte le nombre de lignes parlées par chaque personnage\n",
        "\n",
        "# Calculate the total number of lines spoken across all seasons\n",
        "total_lines = line_counts.sum()  # Calcule le nombre total de lignes parlées\n",
        "\n",
        "# Calculate the proportion of lines spoken by each character across all seasons\n",
        "proportions = line_counts / total_lines  # Calcule la proportion de lignes parlées par chaque personnage\n",
        "\n",
        "print(\"Number of lines spoken by each character across all seasons:\")  # Affiche un message\n",
        "print(line_counts)  # Affiche le nombre de lignes par personnage\n",
        "print(\"\\nTotal number of lines spoken across all seasons:\", total_lines)  # Affiche le total des lignes\n",
        "print(\"\\nProportion of lines spoken by each character across all seasons:\")  # Affiche un message\n",
        "print(proportions)  # Affiche les proportions\n",
        "\n",
        "# Determine if participation is balanced across all seasons\n",
        "balanced_threshold = 0.5  # Définit un seuil pour l'équilibre de la participation\n",
        "if proportions.min() / proportions.max() > balanced_threshold:  # Vérifie si la participation est équilibrée\n",
        "    print(\"\\nParticipation is balanced across all seasons.\")  # Affiche un message si équilibré\n",
        "else:\n",
        "    print(\"\\nParticipation is not balanced across all seasons.\")  # Affiche un message si non équilibré"
      ],
      "metadata": {
        "id": "8SFPmtYHQR4h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Importation pour vectoriser le texte\n",
        "from sklearn.metrics.pairwise import cosine_similarity  # Importation pour calculer la similarité cosinus\n",
        "import itertools  # Importation pour les fonctions d'itération\n",
        "\n",
        "# Define a function to calculate language style matching between two individuals\n",
        "def calculate_lsm(lines1, lines2):  # Fonction pour calculer le matching de style de langage\n",
        "    # Combine lines of dialogue into single documents for each individual\n",
        "    doc1 = ' '.join(lines1)  # Combine les lignes de la première personne\n",
        "    doc2 = ' '.join(lines2)  # Combine les lignes de la deuxième personne\n",
        "\n",
        "    # Vectorize the documents using TF-IDF representation\n",
        "    vectorizer = TfidfVectorizer()  # Crée une instance de TfidfVectorizer\n",
        "    tfidf_matrix = vectorizer.fit_transform([doc1, doc2])  # Applique la vectorisation TF-IDF aux documents\n",
        "\n",
        "    # Calculate cosine similarity between the TF-IDF vectors\n",
        "    similarity_matrix = cosine_similarity(tfidf_matrix)  # Calcule la similarité cosinus entre les vecteurs TF-IDF\n",
        "\n",
        "    # Return the cosine similarity score\n",
        "    return similarity_matrix[0, 1]  # Retourne le score de similarité cosinus\n",
        "\n",
        "# Define a function to calculate language style matching for all pairs of individuals\n",
        "def calculate_lsm_for_all_pairs(df):  # Fonction pour calculer le matching de style de langage pour tous les pairs\n",
        "    # Group lines of dialogue by character\n",
        "    grouped_lines = df.groupby('char')['line'].apply(list).reset_index()  # Regroupe les lignes de dialogue par personnage\n",
        "\n",
        "    # Generate all pairs of individuals\n",
        "    pairs = list(itertools.combinations(grouped_lines['char'], 2))  # Génère toutes les combinaisons de personnages\n",
        "\n",
        "    # Calculate language style matching for each pair\n",
        "    lsm_scores = {}  # Dictionnaire pour stocker les scores LSM\n",
        "    for pair in pairs:  # Itère à travers chaque paire de personnages\n",
        "        lines1 = grouped_lines[grouped_lines['char'] == pair[0]]['line'].iloc[0]  # Récupère les lignes du premier personnage\n",
        "        lines2 = grouped_lines[grouped_lines['char'] == pair[1]]['line'].iloc[0]  # Récupère les lignes du deuxième personnage\n",
        "        lsm_score = calculate_lsm(lines1, lines2)  # Calcule le score LSM pour la paire\n",
        "        lsm_scores[f\"{pair[0]} vs {pair[1]}\"] = lsm_score  # Stocke le score dans le dictionnaire\n",
        "\n",
        "    return lsm_scores  # Retourne les scores LSM\n",
        "\n",
        "# Calculate language style matching for all pairs of individuals\n",
        "lsm_scores = calculate_lsm_for_all_pairs(df)  # Calcule les scores LSM pour tous les pairs\n",
        "\n",
        "# Display language style matching scores\n",
        "for pair, score in lsm_scores.items():  # Itère à travers les scores LSM\n",
        "    print(f\"{pair}: LSM Score = {score:.2f}\")  # Affiche le score LSM pour chaque paire"
      ],
      "metadata": {
        "id": "nnzoNHdNQb_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd  # Importation de pandas pour la manipulation de données\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "data = {  # Crée un dictionnaire de données d'exemple\n",
        "    'char': ['Rachel', 'Ross', 'Monica', 'Chandler', 'Joey', 'Phoebe', 'Rachel', 'Monica', 'Rachel'],\n",
        "    'line': ['Hi Ross!', 'Hey Rachel.', 'What are you doing?', 'Just hanging out.', 'Wanna grab a coffee?', 'Sure!', 'How was your day?', 'Busy as always.', 'Same here.'],\n",
        "    'season': [1, 1, 1, 1, 1, 1, 2, 2, 2],\n",
        "    'episode': [1, 1, 1, 1, 1, 1, 2, 2, 2]\n",
        "}\n",
        "df = pd.DataFrame(data)  # Crée un DataFrame à partir des données d'exemple\n",
        "\n",
        "# Function to calculate turn-taking and interruptions\n",
        "def calculate_turn_taking_and_interruptions(df):  # Fonction pour calculer le tour de parole et les interruptions\n",
        "    turn_counts = {}  # Dictionnaire pour stocker le nombre de tours\n",
        "    interruptions = 0  # Compteur d'interruptions\n",
        "\n",
        "    # Iterate over each row in the DataFrame\n",
        "    for index, row in df.iterrows():  # Itère à travers chaque ligne du DataFrame\n",
        "        current_speaker = row['char']  # Récupère le personnage actuel\n",
        "        # Check for interruptions\n",
        "        if index > 0:  # Vérifie si ce n'est pas la première ligne\n",
        "            previous_speaker = df.loc[index - 1, 'char']  # Récupère le personnage précédent\n",
        "            if current_speaker != previous_speaker:  # Vérifie s'il y a une interruption\n",
        "                interruptions += 1  # Incrémente le compteur d'interruptions\n",
        "        # Count turns for each character\n",
        "        if current_speaker in turn_counts:  # Vérifie si le personnage est déjà dans le dictionnaire\n",
        "            turn_counts[current_speaker] += 1  # Incrémente le compteur de tours\n",
        "        else:\n",
        "            turn_counts[current_speaker] = 1  # Initialise le compteur de tours pour ce personnage\n",
        "\n",
        "    return turn_counts, interruptions  # Retourne le dictionnaire des tours et le nombre d'interruptions\n",
        "\n",
        "# Calculate turn-taking and interruptions\n",
        "turn_counts, interruptions = calculate_turn_taking_and_interruptions(df)  # Calcule les tours de parole et les interruptions\n",
        "\n",
        "# Print the results\n",
        "print(\"Turn Counts:\")  # Affiche un message\n",
        "for char, count in turn_counts.items():  # Itère à travers les résultats\n",
        "    print(f\"{char}: {count} turns\")  # Affiche le nombre de tours pour chaque personnage\n",
        "\n",
        "print(\"\\nInterruptions:\", interruptions)  # Affiche le nombre d'interruptions\n",
        "\n",
        "import pandas as pd  # Importation de pandas pour la manipulation de données\n",
        "from collections import Counter  # Importation de Counter pour compter les occurrences\n",
        "\n",
        "# Sample DataFrame (replace this with your actual data)\n",
        "data = {  # Crée un dictionnaire de données d'exemple\n",
        "    'char': ['Rachel', 'Ross', 'Monica', 'Chandler', 'Joey', 'Phoebe'],\n",
        "    'line': ['I love shopping!', 'How are you?', \"Let's cook dinner.\", 'Could you pass the remote?', 'How you doin?', 'I wrote a new song.']\n",
        "}\n",
        "df = pd.DataFrame(data)  # Crée un DataFrame à partir des données d'exemple\n",
        "\n",
        "# Function to extract keywords from text\n",
        "def extract_keywords(text):  # Fonction pour extraire des mots-clés d'un texte\n",
        "    # Split text into words and remove punctuation\n",
        "    words = text.lower().split()  # Sépare le texte en mots et le met en minuscules\n",
        "    # Define stopwords (words to ignore)\n",
        "    stopwords = ['a', 'an', 'the', 'is', 'are', 'and', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'to', 'of', 'for', 'in', 'on', 'with']  # Liste des mots à ignorer\n",
        "    # Remove stopwords and count word frequencies\n",
        "    word_counts = Counter(word for word in words if word not in stopwords)  # Compte les occurrences des mots qui ne sont pas des mots à ignorer\n",
        "    # Return the most common keywords\n",
        "    return word_counts.most_common()  # Retourne les mots les plus fréquents\n",
        "\n",
        "# Apply keyword extraction to each line of dialogue\n",
        "df['keywords'] = df['line'].apply(extract_keywords)  # Applique l'extraction de mots-clés à chaque ligne de dialogue\n",
        "\n",
        "# Display the DataFrame with extracted keywords\n",
        "print(df[['char', 'line', 'keywords']])  # Affiche le DataFrame avec les mots-clés extraits"
      ],
      "metadata": {
        "id": "ESAZa5A5Qdgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json  # Importation de json pour travailler avec des fichiers JSON\n",
        "\n",
        "def analyze_affiliative_language(data):  # Fonction pour analyser le langage affiliatif\n",
        "    inclusive_pronouns = ['we', 'us', 'our', 'ours', 'ourselves']  # Liste des pronoms inclusifs\n",
        "    terms_of_endearment = ['dear', 'darling', 'sweetheart', 'honey', 'babe', 'love', 'sweetie', 'baby']  # Liste des termes d'affection\n",
        "\n",
        "    affiliative_count = 0  # Compteur pour le langage affiliatif\n",
        "\n",
        "    # Split the data into individual turns\n",
        "    turns = data.split('\\n')  # Sépare les données en tours individuels\n",
        "\n",
        "    # Iterate through each turn\n",
        "    for turn in turns:  # Itère à travers chaque tour\n",
        "        # Split the turn into words\n",
        "        words = turn.lower().split()  # Sépare le tour en mots et le met en minuscules\n",
        "\n",
        "        # Check for inclusive pronouns\n",
        "        for word in words:  # Itère à travers les mots\n",
        "            if word in inclusive_pronouns:  # Vérifie si le mot est un pronom inclusif\n",
        "                affiliative_count += 1  # Incrémente le compteur affiliatif\n",
        "\n",
        "        # Check for terms of endearment\n",
        "        for word in words:  # Itère à travers les mots\n",
        "            if word in terms_of_endearment:  # Vérifie si le mot est un terme d'affection\n",
        "                affiliative_count += 1  # Incrémente le compteur affiliatif\n",
        "\n",
        "    return affiliative_count  # Retourne le compteur affiliatif\n",
        "\n",
        "# Define the file path\n",
        "file_path = \"/home/katia/Documents/BrainHack/BrainHack_projects/data/json/json_aa/json_aa/friends_s01e01a_aa.json\"  # Définit le chemin du fichier JSON\n",
        "\n",
        "# Read the JSON file\n",
        "with open(file_path, 'r') as file:  # Ouvre le fichier JSON en mode lecture\n",
        "    data = file.read()  # Lit le contenu du fichier\n",
        "\n",
        "# Analyze affiliative language in the data\n",
        "count = analyze_affiliative_language(data)  # Analyse le langage affiliatif dans les données\n",
        "print(\"Affiliative language count:\", count)  # Affiche le nombre de langage affiliatif trouvé"
      ],
      "metadata": {
        "id": "xbBIYzw6N_We"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}